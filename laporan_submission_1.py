# -*- coding: utf-8 -*-
"""laporan_submission_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ijg50OoFq_zmWV0HrN_qfuxEY-Fy9uB7

##Inisialisasi & Impor Library
"""

!pip install yfinance
!pip install --upgrade yfinance

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
from sklearn.impute import SimpleImputer

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, GRU
from statsmodels.tsa.arima.model import ARIMA

"""##Data Loading"""

# Ambil data USD/IDR
df = yf.download("USDIDR=X", interval='1h')
df = df[['Open', 'High', 'Low', 'Close', 'Volume']]
df

"""##Data Understanding"""

df.info()

print('Total missing value in the dataframe:', df.isnull().sum().sum(), 'records')

print('Columns with missing value:')
print(df.isnull().sum())

col_with_missing = [col for col in df.columns if df[col].isnull().any()]
print('Column with missing value:', col_with_missing)

imputer = SimpleImputer()
if col_with_missing:
    df[col_with_missing] = imputer.fit_transform(df[col_with_missing])
else:
    print("No columns with missing values found. Skipping imputation.")

df.head()

print('Total missing value in the dataframe:', df.isnull().sum().sum(), 'records')

df.describe()

numerical_col = [col for col in df.columns if df[col].dtypes == 'float64']
plt.figure(figsize=(15,8))
sns.boxplot(data=df[numerical_col])
plt.show()

"""**Univariate Analysis**"""

cols = 3
rows = 2
fig = plt.figure(figsize=(cols * 5, rows * 5))

for i, col in enumerate(numerical_col):
  ax = fig.add_subplot(rows, cols, i + 1)
  sns.histplot(x=df[col], bins=30, kde=True, ax=ax)
fig.tight_layout()
plt.show()

"""**Multivariate Analysis**"""

sns.pairplot(df[numerical_col], diag_kind='kde')
plt.show()

plt.figure(figsize=(15,8))
corr = df[numerical_col].corr().round(2)
sns.heatmap(data=corr, annot=True, vmin=-1, vmax=1, cmap='Blues', linewidth=1)
plt.title('Correlation matrix for numerical feature', size=15)
plt.show()

"""##Data Preparation"""

df = df[['Close']]
df.head()

# Normalisasi data ke rentang 0-1
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_dataset = scaler.fit_transform(df)

train_size = int(len(scaled_dataset) * 0.80)
test_size = len(scaled_dataset) - train_size
train_data, test_data = scaled_dataset[0:train_size,:], scaled_dataset[train_size:len(scaled_dataset),:]

# Fungsi untuk membuat dataset sekuensial
def create_sequences(df, look_back=1):
    X, Y = [], []
    for i in range(len(df) - look_back - 1):
        a = df[i:(i + look_back), 0]
        X.append(a)
        Y.append(df[i + look_back, 0])
    return np.array(X), np.array(Y)

# look_back adalah jumlah step waktu sebelumnya yang digunakan untuk prediksi step berikutnya
look_back = 30
X_train, y_train = create_sequences(train_data, look_back)
X_test, y_test = create_sequences(test_data, look_back)

# Reshape input menjadi [samples, time steps, features] yang diperlukan oleh LSTM/GRU
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

print(f"Ukuran X_train: {X_train.shape}")
print(f"Ukuran y_train: {y_train.shape}")
print(f"Ukuran X_test: {X_test.shape}")
print(f"Ukuran y_test: {y_test.shape}")

"""##Modeling"""

#LSTM
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(LSTM(50, return_sequences=False))
    model.add(Dropout(0.2))
    model.add(Dense(25))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

#BILSTM
def build_bidirectional_lstm_model(input_shape):
    model = Sequential()
    model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(Bidirectional(LSTM(50, return_sequences=False)))
    model.add(Dropout(0.2))
    model.add(Dense(25))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

#GRU
def build_gru_model(input_shape):
    model = Sequential()
    model.add(GRU(50, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(GRU(50, return_sequences=False))
    model.add(Dropout(0.2))
    model.add(Dense(25))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

input_shape = (X_train.shape[1], 1)

epochs = 100
batch_size = 32

# Model LSTM
print("\nMelatih Model LSTM...")
lstm_model = build_lstm_model(input_shape)
history_lstm = lstm_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)
lstm_model.summary()

# Model Bidirectional LSTM
print("\nMelatih Model Bidirectional LSTM...")
bilstm_model = build_bidirectional_lstm_model(input_shape)
history_bilstm = bilstm_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)
bilstm_model.summary()

# Model GRU
print("\nMelatih Model GRU...")
gru_model = build_gru_model(input_shape)
history_gru = gru_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)
gru_model.summary()

# Prediksi menggunakan model LSTM
train_predict_lstm = lstm_model.predict(X_train)
test_predict_lstm = lstm_model.predict(X_test)

# Prediksi menggunakan model Bidirectional LSTM
train_predict_bilstm = bilstm_model.predict(X_train)
test_predict_bilstm = bilstm_model.predict(X_test)

# Prediksi menggunakan model GRU
train_predict_gru = gru_model.predict(X_train)
test_predict_gru = gru_model.predict(X_test)

train_predict_lstm = scaler.inverse_transform(train_predict_lstm)
y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))
test_predict_lstm = scaler.inverse_transform(test_predict_lstm)
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

train_predict_bilstm = scaler.inverse_transform(train_predict_bilstm)
test_predict_bilstm = scaler.inverse_transform(test_predict_bilstm)

train_predict_gru = scaler.inverse_transform(train_predict_gru)
test_predict_gru = scaler.inverse_transform(test_predict_gru)

"""##Evaluasi"""

def plot_predictions(model_name, train_actual, train_predict, test_actual, test_predict, look_back, scaled_dataset):
    plt.figure(figsize=(15,6))

    # Plot baseline dan prediksi training
    train_predict_plot = np.empty_like(scaled_dataset)
    train_predict_plot[:, :] = np.nan
    train_predict_plot[look_back:len(train_predict)+look_back, :] = train_predict

    # Plot baseline dan prediksi testing
    test_predict_plot = np.empty_like(scaled_dataset)
    test_predict_plot[:, :] = np.nan
    # Penyesuaian indeks untuk test_predict_plot
    test_start_index = len(train_predict) + (look_back * 2) + 1
    test_predict_plot[test_start_index:len(scaled_dataset)-1, :] = test_predict


    plt.plot(scaler.inverse_transform(scaled_dataset), label='Data Aktual Keseluruhan')
    plt.plot(train_predict_plot, label='Prediksi Training')
    plt.plot(test_predict_plot, label='Prediksi Testing')
    plt.title(f'Prediksi Harga USD/IDR menggunakan {model_name}')
    plt.xlabel('Waktu')
    plt.ylabel('Harga USD/IDR')
    plt.legend()
    plt.show()

# Visualisasi untuk LSTM
plot_predictions('LSTM', y_train_actual, train_predict_lstm, y_test_actual, test_predict_lstm, look_back, scaled_dataset)

# Visualisasi untuk Bidirectional LSTM
plot_predictions('Bidirectional LSTM', y_train_actual, train_predict_bilstm, y_test_actual, test_predict_bilstm, look_back, scaled_dataset)

# Visualisasi untuk GRU
plot_predictions('GRU', y_train_actual, train_predict_gru, y_test_actual, test_predict_gru, look_back, scaled_dataset)

# Setelah melatih LSTM
final_lstm_train_loss = history_lstm.history['loss'][-1]
final_lstm_val_loss = history_lstm.history['val_loss'][-1]
print(f"LSTM Final Train Loss (MSE): {final_lstm_train_loss}")
print(f"LSTM Final Validation Loss (MSE): {final_lstm_val_loss}")

# Setelah melatih BiLSTM
final_bilstm_train_loss = history_bilstm.history['loss'][-1]
final_bilstm_val_loss = history_bilstm.history['val_loss'][-1]
print(f"BiLSTM Final Train Loss (MSE): {final_bilstm_train_loss}")
print(f"BiLSTM Final Validation Loss (MSE): {final_bilstm_val_loss}")

# Setelah melatih GRU
final_gru_train_loss = history_gru.history['loss'][-1]
final_gru_val_loss = history_gru.history['val_loss'][-1]
print(f"GRU Final Train Loss (MSE): {final_gru_train_loss}")
print(f"GRU Final Validation Loss (MSE): {final_gru_val_loss}")

# Visualisasi loss
plt.figure(figsize=(12, 6))
plt.plot(history_lstm.history['loss'], label='LSTM Train Loss')
plt.plot(history_lstm.history['val_loss'], label='LSTM Test Loss')
plt.plot(history_bilstm.history['loss'], label='BiLSTM Train Loss')
plt.plot(history_bilstm.history['val_loss'], label='BiLSTM Test Loss')
plt.plot(history_gru.history['loss'], label='GRU Train Loss')
plt.plot(history_gru.history['val_loss'], label='GRU Test Loss')
plt.title('Model Loss Comparison')
plt.ylabel('Loss (MSE)')
plt.xlabel('Epoch')
plt.legend()
plt.show()